services:
  ml_backend_example:
    build:
      context: .
    volumes:
      - ./:/app:z
      - ./cache:/app/cache  # Model weights and labels cache
      - ./huggingface_cache:/root/.cache/huggingface
      - ./pytorch_cache:/root/.cache/torch
    ports:
      - "2003:2000"
    extra_hosts:
      - minio:host-gateway
    networks:
      - antenna_network
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [ gpu ]

networks:
  antenna_network:
    name: antenna_network
